{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNLZC1VBHhFNjpcw7MWKDa+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NirmalMathi/DAT8/blob/master/Pytorch_DRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeisjiRYYauy",
        "colab_type": "text"
      },
      "source": [
        "# **Deep Learning with PyTorch**\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWb9wc2TYdy0",
        "colab_type": "text"
      },
      "source": [
        "In the previous chapter, we became familiar with open source libraries, which provided with a collection of reinforcement learning (RL) environments. \n",
        "    However, recent developments in RL,and especially its combination with deep learning (DL), now make it possible to solve much more challenging problems than ever before.\n",
        "    This is partly due to the development of DL methods and tools. This chapter is dedicated to one such tool, **PyTorch**, which enables us to implement complex DL models with just a bunch of lines of Python code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvrdVqQEYnQJ",
        "colab_type": "text"
      },
      "source": [
        "In this chapter,We are going to see\n",
        "\n",
        "- Specific PyTorch library  and implementation details (assuming that you are already familiar with DL fundamentals)\n",
        "- Higher-level libraries on top of **PyTorch**, with the aim of simplifying common DL problems\n",
        "- The library **PyTorch ignite**, which will be used in some examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGfr5dZzY0ox",
        "colab_type": "text"
      },
      "source": [
        "#**Tensors and its creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjIHQwsVY8ab",
        "colab_type": "text"
      },
      "source": [
        "A tensor is the fundamental building block of all DL toolkits.**Tensors is a multi dimensioal arrays.**\n",
        "\n",
        "We call single dimensional arrays as **vectors**,two dimensional arrays as **matrix** and three/higher dimensional arrays as **Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THLS1b8vZM37",
        "colab_type": "code",
        "outputId": "18c6407e-620c-4e25-886d-0c6621988ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_pEs2gEaeHH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19tb_kPMafB3",
        "colab_type": "code",
        "outputId": "ef1bf4e2-f9e6-491c-c023-6e0d3eb3da81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itMRd5nka-Yk",
        "colab_type": "text"
      },
      "source": [
        "!pip install torch\n",
        "\n",
        "\n",
        "!pip install pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWL4H2PFbBtT",
        "colab_type": "text"
      },
      "source": [
        "!conda install pytorch torchvision cpuonly -c pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_alz_iPXbF7g",
        "colab_type": "text"
      },
      "source": [
        "Apart from dimensions, a tensor is characterized by the type of its elements. There are eight types supported by PyTorch: **three float types** (16-bit, 32-bit, and 64-bit) and **five integer types** (8-bit signed, 8-bit unsigned, 16-bit, 32-bit, and 64-bit). \n",
        "\n",
        "Tensors of different types are represented by different classes, with the most commonly used being **torch.FloatTensor** (corresponding to a 32-bit float),**torch.ByteTensor** (an 8-bit unsigned integer), and **torch.LongTensor** (a 64-bit signed integer). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9WBVFh3cNc3",
        "colab_type": "text"
      },
      "source": [
        "First way to create tensors is by below way of code,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUQZROLObEFl",
        "colab_type": "code",
        "outputId": "a8097646-a208-4690-c5ce-95eca75f1aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "a = torch.FloatTensor(3, 5)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.3527e-36, 0.0000e+00, 3.7835e-44, 0.0000e+00,        nan],\n",
              "        [0.0000e+00, 1.3733e-14, 6.4069e+02, 4.3066e+21, 1.1824e+22],\n",
              "        [4.3066e+21, 6.3828e+28, 3.8016e-39, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba5aSm5jbbS6",
        "colab_type": "text"
      },
      "source": [
        "In above example, we imported both PyTorch and NumPy and created anuninitialized tensor of size 3×2. By default, PyTorch allocates memory for the tensor, but doesn't initialize it with anything.\n",
        "\n",
        "In case if we want to make the values in Tensors to zero,we have to issue below below piece of code,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrzY1wGJbVYn",
        "colab_type": "code",
        "outputId": "d3bc5f9c-7000-46f6-9184-8cd2a580ec3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a.zero_() #inplace"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5tO9hrXbtY9",
        "colab_type": "text"
      },
      "source": [
        "- **Inplace and functional**\n",
        "\n",
        "\n",
        "If we use any function with underscore atlast then it will be reflected in original data,this kind of approach is called **Inplace** and its very useful in memory and performance prespective\n",
        "\n",
        "The **functional** equivalent creates a copy of the tensor withthe performed modification, leaving the original tensor untouched.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOZx1dHGcJr6",
        "colab_type": "text"
      },
      "source": [
        "Second way to create a tensor by its **constructor** is to provide a Python iterable (for example, a list or tuple), which will be used as the contents of the newly created tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JL5fSK5bnFc",
        "colab_type": "code",
        "outputId": "53bf2cde-2f1d-49ab-9f0c-8270ec1bc594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "torch.FloatTensor([[1,2,3],[3,2,1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [3., 2., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gfxPecrchmi",
        "colab_type": "text"
      },
      "source": [
        "Third way is to create tensors by using **Numpy** **arrays**,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg-PUZMFcg-R",
        "colab_type": "code",
        "outputId": "550a66ab-f6a1-4664-959f-c9505ace1442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "n = np.zeros(shape=(3, 2))\n",
        "n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqkbOOn6cflb",
        "colab_type": "code",
        "outputId": "023858a8-dfba-4cb3-99f6-882dbc0af203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "b=torch.tensor(n)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vSsE9k3cumU",
        "colab_type": "text"
      },
      "source": [
        "If we want to **change the dtype**,then we can specify that in **torch.tensors** with required dtype as below,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhqFZ-J0caYs",
        "colab_type": "code",
        "outputId": "813f2ae9-dbb1-43cd-8a56-421fa6502fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "b=torch.tensor(n, dtype=torch.float32)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3_p-hJnc1E6",
        "colab_type": "text"
      },
      "source": [
        "Since the **0.4.0 release**, PyTorch has supported **zero-dimensional tensors** that correspond to scalar values Such tensors can be the result of some operations, such as summing all values in a tensor.\n",
        "\n",
        "zero-dimensional tensors are natively supported and returned by the appropriate functions, and they can be created by the **torch.tensor()** function. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njl5req8c-NN",
        "colab_type": "text"
      },
      "source": [
        "For accessing the actual Python value of such a tensor, there is the special **item()** method\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7smH1a5wcxzg",
        "colab_type": "code",
        "outputId": "d42b94fb-b4e2-41b8-d820-025f9d9dc4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "print(\"tensors are\",a)\n",
        "\n",
        "s = a.sum()\n",
        "print(\"sum of tensors\",s)\n",
        "\n",
        "i=s.item()\n",
        "print(\"value of tensors\",i)\n",
        "\n",
        "torch.tensor(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensors are tensor([1, 2, 3])\n",
            "sum of tensors tensor(6)\n",
            "value of tensors 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfjSbIKfdIkk",
        "colab_type": "text"
      },
      "source": [
        "For exploring more with pytorch,please refer below url,\n",
        "\n",
        "**http://pytorch.org/docs/**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEARZWYYdRVK",
        "colab_type": "text"
      },
      "source": [
        "# **GPU** **tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec3v4-bNdU8P",
        "colab_type": "text"
      },
      "source": [
        "PyTorch transparently supports **CUDA GPUs**, which means that all operations have two versions—CPU and GPU—that are\n",
        "automatically selected. \n",
        "\n",
        "Every tensor type that we saw above is for CPU and has its GPU equivalent. The only difference is that GPU tensors reside in the\n",
        "**torch.cuda package**, instead of just torch . \n",
        "\n",
        "For example,**torch.FloatTensor** is a 32-bit float tensor that resides in CPU memory,but **torch.cuda.FloatTensor** is its GPU counterpart.\n",
        "\n",
        "To convert from CPU to GPU, there is a tensor method, **to(device)** , that creates a copy of the tensor to a specified device (this could be CPU or GPU)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG8g11qSdDpS",
        "colab_type": "code",
        "outputId": "fd8b618b-21a5-4a2d-d775-32a068097520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = torch.FloatTensor([2,3])\n",
        "print(a)\n",
        "\n",
        "ca = a.to('cuda');\n",
        "ca\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 3.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY5AyirUd2P1",
        "colab_type": "text"
      },
      "source": [
        "**Here, we created a tensor on CPU, then copied it to GPU memory.**\n",
        "\n",
        "Both copies can be used in computations and all GPU-specific machinery is transparent to the user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuL5mJ3denD",
        "colab_type": "code",
        "outputId": "f4c772c4-ac80-4a23-cdf5-cdeda552ae93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "b= a + 1\n",
        "print(\"addition with 1 in cpu is\",b)\n",
        "c=ca + 1\n",
        "print(\"addition with 1 in GPU is\",c)\n",
        "d=ca.device\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "addition with 1 in cpu is tensor([3., 4.])\n",
            "addition with 1 in GPU is tensor([3., 4.], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OfyhxyeGKD",
        "colab_type": "text"
      },
      "source": [
        "# Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYscV6gleInX",
        "colab_type": "text"
      },
      "source": [
        "Computing gradients was extremely painful to implement and debug, even for the simplest neural network (NN). You had to calculate derivatives for all your functions, then apply the chain rule, and then implement the result of the calculations,thinking that everything is correct. \n",
        "\n",
        "This could be a very useful exercise for understanding the nuts and bolts of DL, but it wasn't something that you wanted to repeat over and over again by experimenting with different NN architectures.\n",
        "\n",
        "Luckily, those days have gone now, Now, defining an NN of hundreds of layers requires nothing more than assembling it from predefined building blocks or, in the extreme case of you doing something fancy, defining the transformation expression manually.\n",
        "\n",
        "All gradients will be carefully calculated for you, backpropagated, and applied to the network. To be able to achieve this, you need to define your network architecture in terms of the DL library used, which can be different in the details, but generally must be the same\n",
        "\n",
        "\n",
        "\n",
        "There are two approaches for calculating gradients:\n",
        "\n",
        "- **Static graph**: In this method, you need to define your calculations in advance and it won't be possible to change them at later stage. The graph will be processed and optimized by the DL library before any computation is made. This model is implemented in TensorFlow (<2), Theano, and many other DL toolkits.\n",
        "\n",
        "\n",
        "- **Dynamic graph**: You don't need to define your graph in advance exactly as it will be executed; you just need to execute operations that you want to use for data transformation on your actual data. During this time, the library will record the order of the operations performed, and when you ask it to calculate gradients, it will unroll its history of operations, accumulating the gradients of the network parameters. This method is also called **notebook gradients** and it is implemented in PyTorch\n",
        "\n",
        "Both methods have their strengths and weaknesses. For example, **static graph** is usually **faster**, as all computations can be moved to the GPU, minimizing the data transfer overhead. \n",
        "\n",
        "On the other hand, although **dynamic graph** has a **higher computation overhead**, it gives a developer much more freedom.\n",
        "\n",
        " For example, they can say, \"For this piece of data, I can apply this network two times, and for this piece of data, I'll use a completely different model with gradients clipped by the batch mean. In the end, it's just a Python library with a bunch of functions, so just call them and let the library takes the pain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJsRfpMfWBy",
        "colab_type": "text"
      },
      "source": [
        "# **Tensors** **and** **gradients**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHZkY9bkfb2J",
        "colab_type": "text"
      },
      "source": [
        "PyTorch tensors have a **built-in gradient calculation** and tracking machinery, so all you need to do is convert the data into tensors and perform computations using the tensor methods and functions provided by torch library.\n",
        "\n",
        "There are several **attributes** it has,\n",
        "\n",
        "- **grad** : A property that holds a tensor of the **same shape containing computed gradients**\n",
        "- **is_leaf : True**, if this tensor was constructed by the user and\n",
        "\n",
        " - **is_leaf : False**, if the object is a result of function transformation.\n",
        "- **requires_grad : True** if this tensor requires gradients to be calculated.By default, the constructor has\n",
        "- **requires_grad : False** , so if you want gradients to be calculated for your tensor, then you need to explicitly say so.\n",
        "\n",
        "Lets consider below example,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDO2907WeBVs",
        "colab_type": "code",
        "outputId": "52b2db8e-9a12-4fc8-8825-f8aa89530b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.tensor([1.0, 1.0], requires_grad=True)\n",
        "b = torch.tensor([2.0, 2.0])\n",
        "print(a,b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1.], requires_grad=True) tensor([2., 2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hctffdmDgNo8",
        "colab_type": "text"
      },
      "source": [
        "In the above code, we created two tensors. \n",
        "The **first requires gradients** to be calculated and the **second doesn't requires gradients**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFCPaXbtgITV",
        "colab_type": "code",
        "outputId": "304a9fe0-50c1-415e-f399-8c76bde3404b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "summing = a+b\n",
        "print(summing)\n",
        "res = (summing*2).sum()\n",
        "print(res)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3.], grad_fn=<AddBackward0>)\n",
            "tensor(12., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEsIa6zgwDX",
        "colab_type": "text"
      },
      "source": [
        "If we check the attributes that we calcualted,then we will find that a and b are the leaf nodes and every variable, except b, requires gradients to be calculated:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiHnzKLsgilh",
        "colab_type": "code",
        "outputId": "72955915-a85a-4217-ca13-053461d8f6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.is_leaf, b.is_leaf\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRkUEPchMqa",
        "colab_type": "code",
        "outputId": "88175ba7-18ec-4012-af1f-6d613d4977b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "summing.is_leaf, res.is_leaf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLJzpFwehdij",
        "colab_type": "code",
        "outputId": "fad4f8d4-2e84-4439-f720-e29ca9809cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a.requires_grad\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNEdNZPXhj6M",
        "colab_type": "code",
        "outputId": "1e1426aa-19b3-4d94-a3e3-d782f6132bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b.requires_grad\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uSMvpQuhSHF",
        "colab_type": "text"
      },
      "source": [
        "To calculate the gradients of our graph:\n",
        "\n",
        "We should keep **retain_graph = True**,because pytorch uses **dynamic computational graph** where the non-leaf buffers gets destroyed the first time **backward()** is called and hence, there’s no path to navigate to the leaves when **backward** is invoked the second time.Hence to overcome this we use **retain_graph = True** in backward propagation so that gradients of non leaf tensors will not be destroyed and kept in memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0prcovyhwGg",
        "colab_type": "code",
        "outputId": "10e0940b-607b-4171-844f-a35cdaa2bbb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res.backward( retain_graph=True)\n",
        "a.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OfCNAP1h3mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7KzfJMpom7j",
        "colab_type": "text"
      },
      "source": [
        "Indeed, if we try to check the gradients of\n",
        "b , we get nothing,this is because we didn't define gradient for b tensor.\n",
        "\n",
        "Also,The reason for that is efficiency in terms of computations and memory. In **real life**, our network can have millions of optimized parameters, with hundreds of intermediate operations performed on them. During **gradient descent optimization**, the only things we want to adjust in the model are gradients of loss with respect to model parameters (weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QFr_pAzpSUg",
        "colab_type": "text"
      },
      "source": [
        "# **Building** **Neural** **Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFLn1j-9qBBr",
        "colab_type": "text"
      },
      "source": [
        "In the **torch.nn** package, you can find tons of predefined classes providing you with the basic functionality blocks.\n",
        "\n",
        "All classes in the **torch.nn** packages inherit from the **nn.Module base class**.\n",
        "\n",
        "Let's look at useful methods that all **nn.Module** children provide as follows,\n",
        "\n",
        "**parameters()** :Returns an iterator of all variables that require gradient computation ie..,module weight.\n",
        "\n",
        "**zero_grad()** : initializes all gradients of all parameters to zero.\n",
        "\n",
        "**to(device)** : moves all module parameters to a given device (CPU or GPU).\n",
        "\n",
        "**state_dict()** : returns the dictionary with all module parameters and is useful for model serialization\n",
        "\n",
        "**load_state_dict()** :initializes the module with the state dictionary.\n",
        "\n",
        "All available classes can be found in the documentation at http://pytorch.org/docs.\n",
        "\n",
        "The best way to demonstrate NN blocks is through an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IobvhNkoqAXg",
        "colab_type": "code",
        "outputId": "66d21d88-038d-4592-eb82-e58fcc452296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "a = nn.Sequential(\n",
        "nn.Linear(2, 6),\n",
        "nn.ReLU(),\n",
        "nn.Linear(6, 10),\n",
        "nn.ReLU(),\n",
        "nn.Linear(10, 20),\n",
        "nn.Dropout(p=0.5),\n",
        "nn.Softmax(dim=1))\n",
        "\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=2, out_features=6, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=6, out_features=10, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=10, out_features=20, bias=True)\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZI6I4ySthDV",
        "colab_type": "text"
      },
      "source": [
        "Here, we defined a three-layer NN with softmax on output, applied along dimension 1 (dimension 0 is batch samples), rectified linear unit (ReLU) nonlinearities, and dropout with 0.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr4HHxs4omOn",
        "colab_type": "code",
        "outputId": "58410364-0502-425c-c029-3820ac591919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "b=a(torch.FloatTensor([[10,10]]))\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.8380e-03, 5.5520e-03, 8.5291e-03, 3.3034e-01, 5.6342e-04, 5.5520e-03,\n",
              "         5.5520e-03, 5.5520e-03, 5.5520e-03, 9.0620e-02, 5.5520e-03, 9.4176e-02,\n",
              "         4.1645e-01, 5.5520e-03, 5.5520e-03, 7.9771e-04, 5.5520e-03, 1.3919e-04,\n",
              "         2.4830e-05, 5.5520e-03]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BboeAz1EuEu3",
        "colab_type": "text"
      },
      "source": [
        "So, our mini-batch is successfully traversing through the network..Still not yet finished we need to do important things"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXKaBRrLueGW",
        "colab_type": "text"
      },
      "source": [
        "# **Custom** **layers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "124fSJWxuulu",
        "colab_type": "text"
      },
      "source": [
        "Now will look at how this can be done in a more generic and reusable way for making sequential task below,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BactpvFgokGc",
        "colab_type": "code",
        "outputId": "a7660b08-5673-4b02-fcb0-47cda08e28ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#class creation for inheriting nn.Module..In the constructor, we pass three parameters: the input size, the output size, and the optional dropout probability. \n",
        "#The first thing we need to do is call the parent's constructor to let it initialize itself.\n",
        "\n",
        "class mymodule(nn.Module):\n",
        "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
        "        super(mymodule, self).__init__()\n",
        "        self.pipe = nn.Sequential(\n",
        "            nn.Linear(num_inputs, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, num_classes),\n",
        "            nn.Dropout(p=dropout_prob),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "#the constructor completed, all those fields will be registered automatically\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pipe(x)\n",
        "\n",
        "#Here,we are override the forward function with our implementation of data transformation. \n",
        "#As our module is a very simple wrapper around other layers, we just need to ask them to transform the data.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    net = mymodule(num_inputs=3, num_classes=4)\n",
        "    print(net)\n",
        "    v = torch.FloatTensor([[6,2,6]])\n",
        "    out = net(v)\n",
        "    print(out)\n",
        "    print(\"Cuda's availability is %s\" % torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"Data from cuda: %s\" % out.to('cuda'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mymodule(\n",
            "  (pipe): Sequential(\n",
            "    (0): Linear(in_features=3, out_features=8, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=8, out_features=15, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=15, out_features=4, bias=True)\n",
            "    (5): Dropout(p=0.3, inplace=False)\n",
            "    (6): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "tensor([[0.3520, 0.3520, 0.2100, 0.0859]], grad_fn=<SoftmaxBackward>)\n",
            "Cuda's availability is True\n",
            "Data from cuda: tensor([[0.3520, 0.3520, 0.2100, 0.0859]], device='cuda:0',\n",
            "       grad_fn=<CopyBackwards>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry2gHwVFxBhi",
        "colab_type": "text"
      },
      "source": [
        "The **forward**() method is called for every batch of data, so if you want to do some complex transformations based on the data you need to process, with multiple required parameters and dozens of optional arguments, and its possible and can be done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5OQ0pKIvxyQ",
        "colab_type": "text"
      },
      "source": [
        "# **Loss** **function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4oIyoERx8WH",
        "colab_type": "text"
      },
      "source": [
        "At the time of writing,** PyTorch 1.3.0** contains 20 different loss functions and even own functions can be written,\n",
        "\n",
        "Some of them are,\n",
        "\n",
        "\n",
        "- **nn.MSELoss :** The mean square error between arguments, which is the standard loss for regression problems.\n",
        "\n",
        "- **nn.BCELoss:** Binary cross-entropy loss.This loss expects a single probability value (usually it's the output of the Sigmoid layer)\n",
        "\n",
        "- **nn.CrossEntropyLoss :**Famous \"maximum likelihood\" criteria that are used in multi-class classification problems.This expects raw scores for each class and applies LogSoftmax internally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1J8vw6o2oeI",
        "colab_type": "text"
      },
      "source": [
        "# **Optimizers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzPid28i2wo9",
        "colab_type": "text"
      },
      "source": [
        " The responsibility of the basic optimizer is to take the gradients of model parameters and change these parameters in order to decrease the loss value. By decreasing the loss value, we will get better model performance in future.\n",
        " \n",
        "The most widely known optimisers are as follows:\n",
        " \n",
        "- **SGD** : A vanilla stochastic gradient descent algorithm\n",
        "- **RMSprop** : An optimizer proposed by Geoffrey Hinton\n",
        "- **Adagrad** : An adaptive gradients optimizer\n",
        "- **Adam** : A quite successful and popular combination of both RMSprop and Adagrad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTshOA1E4Vdq",
        "colab_type": "text"
      },
      "source": [
        "# **TensorBoard** **Monitoring**  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQKuYJho4tIk",
        "colab_type": "text"
      },
      "source": [
        "We need a generic solution to track lots of values over time for analysis purposes,we are going to explore one library for such tool known as **TensorboardX**(maintaining by Google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-jHHtpI5acc",
        "colab_type": "text"
      },
      "source": [
        "- **TensorBoard 101**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Im9prng5qhH",
        "colab_type": "text"
      },
      "source": [
        "Pre-requisite is nothing but the **tensorboard and tensorflow packages should be installed**.\n",
        "\n",
        "There are several third-party open source libraries available in market. One of such thing, which is used here is **tensorboardX**\n",
        "\n",
        "**(https://github.com/lanpa/tensorboardX)**. \n",
        "\n",
        "It can be installed with **pip install tensorboardX**\n",
        "\n",
        "Will see this mechanism with simple code below,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK9-v2Le6TWk",
        "colab_type": "code",
        "outputId": "4fb53f0b-6e6b-4e04-ac5c-0c057d7c5865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install tensorboardX\n",
        "import math\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    funcs = {\"sin_math\": math.sin, \"cos_math\": math.cos, \"tan_math\": math.tan}\n",
        "\n",
        "    for angle in range(-360, 360):\n",
        "        angle_rad = angle * math.pi / 180\n",
        "        for name, fun in funcs.items():\n",
        "            val = fun(angle_rad)\n",
        "            writer.add_scalar(name, val, angle)\n",
        "\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (45.2.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdBvpI-E7uNs",
        "colab_type": "text"
      },
      "source": [
        "The result of running this will be zero output on the console, but you will see a new directory created inside the runs directory with a single file. \n",
        "\n",
        "To look at the result, we need to start TensorBoard.\n",
        "\n",
        "**Please hit below command to start TensorBoard**,\n",
        "\n",
        "C:\\Users\\xxx\\Desktop\\Data Science videos --**logdir runs**\n",
        "\n",
        "**TensorBoard 2.0.1 at http://127.0.0.1:6006/**\n",
        "\n",
        "After this,you can open **http://localhost:6006 in your browser** to see something like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdL2GKko9Nrb",
        "colab_type": "text"
      },
      "source": [
        "TensorBoard allows you to analyze not only scalar values but also images, audio, text data, and embeddings, and it can even show you the structure of your network.\n",
        "\n",
        "**Refer to the documentation of tensorboardX and tensorboard for all those features**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxRhzi12stc2",
        "colab_type": "text"
      },
      "source": [
        "# **PyTorch Ignite**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Misb24j1syRE",
        "colab_type": "text"
      },
      "source": [
        "PyTorch is an elegant and flexible library, which is useful for thousands of researchers, DL enthusiasts, industry\n",
        "developers, and others. But it requires you to write more lines of code.Situation whre it all can be used is,\n",
        "\n",
        "- When you have your own optimiser and you have to implement that in NN and check the response.\n",
        "\n",
        "- In case of dealing more with gradients,loss and backpropagation.\n",
        "\n",
        "- calculating training metrics, like loss values, accuracy,confusion matrix and F1-scores\n",
        " \n",
        "- Putting a check point after some iterations or to know when model is best fitted in backpropagation\n",
        "\n",
        "- To change learning rate during run time as a hyperparameter tuning\n",
        "\n",
        "So,when we have to do some kind of above operations,its difficult to write it again and again for every dataset where you want to check gradients,loss,optimization,iterations,etc..,\n",
        "\n",
        "For serving those purpose in DL,PyTorch provided some libraries like **ptlearn,ignite and so on..**\n",
        "\n",
        "Initially we need to understand how these high level libraries work and then we can start using for solving above common problems with just a few lines of code.We will also use these type of high level libraries in latter stage to implement RL problems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlmpe6MXwBO3",
        "colab_type": "text"
      },
      "source": [
        "# **Ignite Concepts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xocquFd_wFUH",
        "colab_type": "text"
      },
      "source": [
        "At a high level, Ignite simplifies the writing of the training loop in PyTorch DL. We all aware that the minimal training loop consists of:\n",
        "\n",
        "- Sampling and sending a batch of training data\n",
        "- Applying an NN to this batch to calculate the loss function\n",
        "- Running backpropagation of the loss to get gradients on the\n",
        "network's parameters in respect to the loss\n",
        "- Asking the optimizer to apply the gradients to the network\n",
        "- epeating until we get good acuuracy result\n",
        "\n",
        "\n",
        "The central piece of Ignite is the **Engine** class, which loops over the data source, applying the processing function to the data batch. \n",
        "\n",
        "In addition to that, Ignite offers the ability to provide functions to be called at specific conditions of the training loop, called Events and could be at the:\n",
        "\n",
        "- starting/end of the whole training process\n",
        "- starting/end of a training epoch \n",
        "- starting/end of a single batch processing\n",
        "\n",
        "for example, if you want to do some calculations every 100 batches or every second epoch,this can be possible with the help of ignite library.\n",
        "\n",
        "Will show you some sample part of code which briefs the iginite concepts,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAogaW7i8vI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "def training(e, b):\n",
        "    optimizer.zero_grad()\n",
        "    x, y = batch()\n",
        "    y_out = model(x)\n",
        "    losses = loss_fn(y_out, y)\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "return losses.item()\n",
        "e = Engine(training)\n",
        "e.run(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG0jGVrMzmoH",
        "colab_type": "text"
      },
      "source": [
        "The use of **Ignite** is in the ability it provides to\n",
        "extend the training loop with existing available functionality. \n",
        "\n",
        "You want to run model validation every 10 epochs?yes,you can do by writing those lines of code and pass it so that it will be done.\n",
        "\n",
        "For further depth,please read the documentation on the official website:\n",
        "**https://pytorch.org/ignite.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AWDILTizjf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}